I have made report for the lecture in notes/report.ipynb.
In this repo, I have tried to synthesize lip motion from audio data using an simplified version of method featured in https://grail.cs.washington.edu/projects/AudioToObama/ .
Below shows example synthesis.
This is the original lip motion.
![](notes/actual_lip.gif)
This is the synthesized lip motion.
![](notes/searched_lip.gif)
