{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "import multiprocessing\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "find . -name \"20*.mp4\" | parallel --no-notice ffmpeg-normalize -v {}\n",
    "```\n",
    "```bash\n",
    "find . -name \"20*.mp4\" | parallel --no-notice ffmpeg -nostdin -i {} {.}.gif -hide_banner\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20161231_Weekly_Address_HD',\n",
       " '20160813_Weekly_Address_HD',\n",
       " '20160625_Weekly_Address_HD',\n",
       " '20170114_Weekly_Address_HD',\n",
       " '20161022_Weekly_Address_HD',\n",
       " '20161001_Weekly_Address_HD',\n",
       " '20161105_Weekly_Address_HD',\n",
       " '20161210_Weekly_Address_HD',\n",
       " '20160910_Weekly_Address_HD',\n",
       " '20160903_Weekly_Address_HD',\n",
       " '20160716_Weekly_Address_HD']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = \"../obama\"\n",
    "savedir = datadir\n",
    "mp4files = !find $datadir -name \"20*.mp4\"\n",
    "fileIDs = [os.path.splitext(os.path.basename(mp4file))[0] for mp4file in mp4files]\n",
    "fileIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training ['20161231_Weekly_Address_HD', '20160813_Weekly_Address_HD', '20160625_Weekly_Address_HD', '20170114_Weekly_Address_HD', '20161022_Weekly_Address_HD', '20161001_Weekly_Address_HD', '20161105_Weekly_Address_HD', '20161210_Weekly_Address_HD', '20160910_Weekly_Address_HD', '20160903_Weekly_Address_HD'], \n",
      " for validation ['20160625_Weekly_Address_HD']\n"
     ]
    }
   ],
   "source": [
    "# Split data for training/validation\n",
    "tID = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "vID = [2]\n",
    "tfileIDs = [fileIDs[id_] for id_ in tID]\n",
    "vfileIDs = [fileIDs[id_] for id_ in vID]\n",
    "print(\"For training {}, \\n for validation {}\".format(tfileIDs, vfileIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_files = [id_+\".gif\" for id_ in fileIDs]\n",
    "tgif_files = [gif_files[id_] for id_ in tID]\n",
    "vgif_files = [gif_files[id_] for id_ in vID]\n",
    "wav_files = [\"normalized-\"+id_+\".wav\" for id_ in fileIDs]\n",
    "twav_files = [wav_files[id_] for id_ in tID]\n",
    "vwav_files = [wav_files[id_] for id_ in vID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_giffile_from_ID(fileID):\n",
    "  return fileID+\".gif\"\n",
    "def get_wavfile_from_ID(fileID):\n",
    "  return \"normalized-\"+fileID+\".wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate lip features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lipfeatures_from_im(im):\n",
    "  # Find all facial features in all the faces in the image\n",
    "  face_landmarks_list = face_recognition.face_landmarks(im)\n",
    "  facial_features = [\n",
    "    'top_lip',\n",
    "    'bottom_lip']\n",
    "  lip_features_list = list()\n",
    "  for face_landmarks in face_landmarks_list:\n",
    "    # Print the location of each facial feature in this image\n",
    "    for facial_feature in facial_features:\n",
    "      for x, y in face_landmarks[facial_feature]:\n",
    "        lip_features_list.append([x, y])\n",
    "  return np.array(lip_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lipfeature_from_ID(fileID):\n",
    "  giffile = os.path.join(datadir, get_giffile_from_ID(fileID))\n",
    "  wavfile = os.path.join(datadir, get_wavfile_from_ID(fileID))\n",
    "  gif_im = Image.open(giffile)\n",
    "  gif_im_array = np.asarray(gif_im)\n",
    "  gif_im_array.flags.writeable = True\n",
    "  (rate,sig) = wav.read(wavfile)\n",
    "  duration_s = sig.shape[0] / rate\n",
    "  sec_per_frame_s = duration_s / gif_im.n_frames\n",
    "  # cal value for t = 0\n",
    "  lip_features = get_lipfeatures_from_im(gif_im_array)\n",
    "  time_stamps = list()\n",
    "  t_s = 0\n",
    "  time_stamps.append(t_s)\n",
    "  gif_lip_features_list = list()\n",
    "  # cal value for t > 0\n",
    "  for frame in range(1, gif_im.n_frames):\n",
    "    gif_im.seek(gif_im.tell() + 1)\n",
    "    gif_im_array = np.asarray(gif_im)\n",
    "    gif_im_array.flags.writeable = True\n",
    "    lip_features = get_lipfeatures_from_im(gif_im_array)\n",
    "    if len(lip_features) > 1:\n",
    "      gif_lip_features_list.append(lip_features)\n",
    "      time_stamps.append(t_s)\n",
    "    t_s += sec_per_frame_s\n",
    "  return time_stamps, np.array(gif_lip_features_list)\n",
    "def map_generate_lipfeature(fileID):\n",
    "  time_stamps, gif_lip_features_mat = generate_lipfeature_from_ID(fileID)\n",
    "  featfile = os.path.join(savedir, \"giffeat_\"+fileID+\".npy\")\n",
    "  tsfile = os.path.join(savedir, \"giftime_\"+fileID+\".npy\")\n",
    "  np.save(featfile, gif_lip_features_mat)\n",
    "  np.save(tsfile, time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's take long time! Be aware to execute.\n",
    "if False:\n",
    "  nthreads = len(fileIDs)\n",
    "  pool = multiprocessing.Pool(nthreads)\n",
    "  pool.map(map_generate_lipfeature, fileIDs)\n",
    "  pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate auido features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
